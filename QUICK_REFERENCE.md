# Quick Reference Guide

## ğŸ“‚ Project Structure at a Glance

```
ğŸ“¦ AIMO3-Solver/
â”œâ”€â”€ ğŸ“ src/                    ğŸ”§ All source code modules
â”‚   â”œâ”€â”€ preprocessing.py       # LaTeX/PDF/text parsing
â”‚   â”œâ”€â”€ reasoning.py           # LLM chain-of-thought
â”‚   â”œâ”€â”€ computation.py         # SymPy symbolic math
â”‚   â”œâ”€â”€ postprocessing.py      # Output formatting
â”‚   â”œâ”€â”€ pipeline.py            # Main orchestrator
â”‚   â”œâ”€â”€ utils.py               # Helper functions
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â””â”€â”€ __init__.py            # Package setup
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â””â”€â”€ aimo3_submission.ipynb  # ğŸ¯ Kaggle submission notebook
â”œâ”€â”€ ğŸ“ datasets/               # ğŸ“Š Input data (download here)
â”œâ”€â”€ ğŸ“ outputs/                # ğŸ“¤ Generated submissions
â”œâ”€â”€ ğŸ“ logs/                   # ğŸ“ Execution logs
â”œâ”€â”€ ğŸ“„ requirements.txt         # Dependencies
â”œâ”€â”€ ğŸ“„ setup.py                # Installation
â”œâ”€â”€ ğŸ“„ .env.template           # Environment config
â”œâ”€â”€ ğŸ“„ DEVELOPMENT.md          # Developer guide
â”œâ”€â”€ ğŸ“„ PROJECT_SUMMARY.md      # ğŸ“‹ This project overview
â””â”€â”€ ğŸ“„ TODO.md                 # Development roadmap
```

---

## ğŸš€ Quick Start

### 1. Setup (5 minutes)
```bash
cd /path/to/aimo3-solver

# Install dependencies
pip install -r requirements.txt

# Create environment file
cp .env.template .env
# Edit .env with your settings

# Install package in development mode
pip install -e .
```

### 2. Test Pipeline (10 minutes)
```python
from src.pipeline import AIMO3Pipeline

pipeline = AIMO3Pipeline()
result = pipeline.solve_single_problem(
    "Compute 2 + 3 Ã— 5",
    problem_id="Test1"
)
print(result['final_answer'])  # Should output 17
```

### 3. Run Kaggle Notebook (variable time)
- Upload notebook to Kaggle
- Or run locally: `jupyter notebook notebooks/aimo3_submission.ipynb`

---

## ğŸ“š Core Modules Overview

| Module | Purpose | Key Functions |
|--------|---------|---|
| `preprocessing.py` | Parse input | `latex_to_text()`, `pdf_to_text()` |
| `reasoning.py` | LLM reasoning | `LLMSolver.solve()` |
| `computation.py` | Math verification | `SymbolicCompute.evaluate_expression()` |
| `postprocessing.py` | Format output | `SubmissionFormatter.save_submission_csv()` |
| `pipeline.py` | Orchestration | `AIMO3Pipeline.solve_batch()` |
| `utils.py` | Utilities | `Evaluator.accuracy()`, `setup_logging()` |
| `config.py` | Configuration | `ModelConfig`, `KaggleConfig` |

---

## âš™ï¸ Configuration

### Important Settings (src/config.py)

```python
# Model choice
ModelConfig.MODEL_NAME = "Open-Orca/orca_mini_3b"

# Generation params
ReasoningConfig.MAX_TOKENS = 512
ReasoningConfig.TEMPERATURE = 0.7

# Kaggle limits
KaggleConfig.CPU_TIMEOUT = 9 * 3600    # 9 hours
KaggleConfig.GPU_TIMEOUT = 5 * 3600    # 5 hours

# Answer range
ComputationConfig.ANSWER_MIN = 0
ComputationConfig.ANSWER_MAX = 99999
```

---

## ğŸ”„ Typical Workflow

### Single Problem
```python
pipeline = AIMO3Pipeline()
result = pipeline.solve_single_problem(problem_text)
print(f"Answer: {result['final_answer']}")
```

### Batch Processing
```python
problems = ["Problem 1", "Problem 2", ...]
result = pipeline.solve_batch(
    problems,
    problem_ids=["P1", "P2", ...],
    save_results=True  # Saves to outputs/ and logs/
)
```

### From CSV
```python
result = pipeline.solve_from_csv(
    "datasets/aimo3_public.csv",
    problem_column="latex_problem",
    id_column="problem_id"
)
```

---

## ğŸ“Š Output Files

After processing, you'll find:

```
outputs/
â”œâ”€â”€ submission.csv           # Kaggle submission format
logs/
â”œâ”€â”€ reasoning_steps.log      # Full reasoning for each problem
â”œâ”€â”€ detailed_results.json    # Complete results with reasoning
â”œâ”€â”€ statistics_*.json        # Statistics and metrics
â””â”€â”€ aimo3_*.log             # Execution logs
```

---

## ğŸ§ª Testing Examples

### Test Preprocessing
```python
from src.preprocessing import latex_to_text
result = latex_to_text(r"$\frac{1}{2} + \frac{1}{3}$")
print(result)  # "frac 1 2 + frac 1 3"
```

### Test Reasoning
```python
from src.reasoning import LLMSolver
solver = LLMSolver("Open-Orca/orca_mini_3b")
result = solver.solve("What is 2 + 2?")
```

### Test Computation
```python
from src.computation import SymbolicCompute
compute = SymbolicCompute()
result = compute.evaluate_expression("2**10")  # 1024
```

### Test Validation
```python
from src.computation import AnswerValidator
validator = AnswerValidator()
answer = validator.validate_integer(150000)  # Clamps to 99999
```

---

## ğŸ› Debugging

### Enable Debug Logging
```python
from src.utils import setup_logging
logger = setup_logging(log_level="DEBUG")
```

### Check Execution Logs
```bash
ls -lh logs/
tail -f logs/aimo3_*.log
```

### Profile Code Performance
```python
from src.utils import timer

@timer
def my_function():
    # Your code here
    pass
```

---

## ğŸ“ˆ Performance Tips

1. **Reduce Token Usage**
   - Shorter, focused prompts
   - `MAX_TOKENS = 256` for faster inference

2. **Batch Processing**
   - Process multiple problems together
   - Better GPU utilization

3. **Model Selection**
   - Smaller models = faster (3B parameters)
   - Larger models = better quality (7B+ parameters)

4. **Caching**
   - Cache LLM outputs
   - Reuse computed results

---

## ğŸ¯ Competition Integration

### For Kaggle Submission
1. **Use the notebook**: `notebooks/aimo3_submission.ipynb`
2. **Upload to Kaggle** as new notebook
3. **Set it as submission**: Enable in notebook settings
4. **Monitor leaderboard**: Check score after submission

### Expected Kaggle Output
```csv
problem_id,predicted_answer
P1,42
P2,100
P3,17
...
```

---

## ğŸ”— Resources

- **Kaggle Competition**: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3
- **HuggingFace Models**: https://huggingface.co/models
- **SymPy Docs**: https://docs.sympy.org/
- **PyTorch Docs**: https://pytorch.org/docs/
- **Transformers Docs**: https://huggingface.co/docs/transformers/

---

## âœ… Checklist Before First Run

- [ ] Dependencies installed: `pip install -r requirements.txt`
- [ ] GPU available (optional): `nvidia-smi`
- [ ] `.env` file created and configured
- [ ] `datasets/` directory ready (will populate with data)
- [ ] `outputs/` directory exists (auto-created)
- [ ] `logs/` directory exists (auto-created)

---

## ğŸ“ Common Issues & Solutions

### Issue: `ModuleNotFoundError: No module named 'src'`
**Solution**: 
```bash
pip install -e .
# or run from project root directory
```

### Issue: `CUDA out of memory`
**Solution**:
- Reduce `MAX_TOKENS` in config
- Use smaller model
- Enable 4-bit quantization

### Issue: Slow inference
**Solution**:
- Profile with @timer decorator
- Reduce sequence length
- Use faster model
- Batch processing

### Issue: No answers generated
**Solution**:
- Check `logs/` for error messages
- Enable DEBUG mode
- Verify LLM is loaded correctly

---

## ğŸ“ Next Steps

1. **Week 1**: Get data working, test pipeline
2. **Week 2**: Fine-tune model, optimize prompts
3. **Week 3**: Generate first submission
4. **Week 4+**: Iterate, improve, reach leaderboard top

---

## ğŸ“„ Documentation Files

- **[DEVELOPMENT.md](DEVELOPMENT.md)** - Complete developer guide
- **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** - Detailed project overview
- **[TODO.md](TODO.md)** - Development roadmap and checklist
- **README.md** - Project overview

---

## ğŸ’¡ Pro Tips

âœ… **Always use the pipeline** - Don't call modules directly if possible
âœ… **Check logs** - They contain useful debugging info
âœ… **Use config.py** - Don't hardcode values
âœ… **Monitor progress** - Use tqdm and logging
âœ… **Save results** - Always save submissions and logs
âœ… **Version control** - Commit working versions

---

**Status**: Phase 1 Complete âœ… | Ready for Phase 2 ğŸš€

*All code tested and documented. Ready to download data and begin training!*
